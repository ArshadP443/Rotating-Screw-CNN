{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshadP443/Rotating-Screw-CNN/blob/main/mitesobjectdetectiontest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing Useful Libraries**\n"
      ],
      "metadata": {
        "id": "VCRTAZfZXHpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "kgmWbOAuXNOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Reproduction\n",
        "torch.manual_seed(2025)\n",
        "torch.cuda.manual_seed(2025)"
      ],
      "metadata": {
        "id": "cUVb6bb5TwaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A Colab pro environment should have >20Gb of total memory.\n",
        "from psutil import virtual_memory\n",
        "colab_pro = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(colab_pro))\n",
        "\n",
        "if colab_pro < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "  # train model with lower settings\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "  # train model with higher settings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_RVz3-JWFJ2",
        "outputId": "c2520c00-8f58-444a-f417-58c9e3478e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Creating the Dataset and DataLoader**"
      ],
      "metadata": {
        "id": "ucFrw1fmYXYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mounting the Google Drive"
      ],
      "metadata": {
        "id": "1h65goq4Sya7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWZU0ffASq9_",
        "outputId": "6d337f28-37cd-428e-9b07-0f925e982d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the Data Frame"
      ],
      "metadata": {
        "id": "2BvNkmp6S_I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Loading the Annotations\n"
      ],
      "metadata": {
        "id": "cwZepfzyUsNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv(r'/content/drive/MyDrive/Object Detection/Annotations.csv')\n",
        "labels_df = labels_df.fillna(-1)\n",
        "labels_df = labels_df.astype(int)"
      ],
      "metadata": {
        "id": "bWETvvRtS-zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creating a Function to Check a Frame's Label"
      ],
      "metadata": {
        "id": "SNl2CMTiVUhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IsPositive(video_number, frame_number):\n",
        "  return int(frame_number in labels_df[f'Video {video_number}'].values)"
      ],
      "metadata": {
        "id": "w1HVcvBXVa2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creating the Main Dataset Dataframe"
      ],
      "metadata": {
        "id": "EU3ymmTBVuoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(IMAGE_TENSORS_DIR)\n",
        "for i, pt_file_name in enumerate(os.listdir(IMAGE_TENSORS_DIR)):\n",
        "\n",
        "  if i < 43:\n",
        "    continue\n",
        "\n",
        "  elif i < 44:\n",
        "\n",
        "    print(pt_file_name)\n",
        "    start_time = time()\n",
        "\n",
        "    video_number = int(re.search(r'\\d+', pt_file_name).group())\n",
        "    video_frames = os.listdir(f'/content/drive/MyDrive/Object Detection/Videos/video{video_number}/')\n",
        "\n",
        "    for j, image_tensor in enumerate(torch.load(pt_file_name)):\n",
        "      data_df = data_df._append({'Video Number' : video_number,\n",
        "                                 'Frame Number': int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')),\n",
        "                                 'Tensor': image_tensor,\n",
        "                                 'Label': IsPositive(video_number, int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')))}, ignore_index=True)\n",
        "\n",
        "    print(f'Finished {pt_file_name} in {round(time() - start_time, 2)} seconds')\n",
        "\n",
        "  else:\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9ZHm09Vyes",
        "outputId": "6dfd0cc3-8bf6-4e38-816c-485c9be0cefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video43.pt\n",
            "Finished video43.pt in 23.97 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(data_df, 'df.pt')"
      ],
      "metadata": {
        "id": "kWsaZApo_99x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the Dataframe"
      ],
      "metadata": {
        "id": "u4fe-3kMwGq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_TENSORS_DIR = '/content/drive/MyDrive/Object Detection/ImageTensors'"
      ],
      "metadata": {
        "id": "68rY3DOVYUuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Object Detection/TrainTensors')\n",
        "data_df = torch.load('df.pt')"
      ],
      "metadata": {
        "id": "-QCZryxkwF2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_df.shape)\n",
        "print(data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvDO1dfUv2Xf",
        "outputId": "b08821b8-af7d-4601-a931-048c88850729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13507, 4)\n",
            "  Video Number Frame Number  \\\n",
            "0           17          443   \n",
            "1           17          411   \n",
            "2           17          478   \n",
            "3           17          413   \n",
            "4           17          437   \n",
            "\n",
            "                                              Tensor  Label  \n",
            "0  [[[tensor(0.6706), tensor(0.6745), tensor(0.67...  False  \n",
            "1  [[[tensor(0.6706), tensor(0.6745), tensor(0.67...  False  \n",
            "2  [[[tensor(0.6745), tensor(0.6745), tensor(0.67...  False  \n",
            "3  [[[tensor(0.6706), tensor(0.6745), tensor(0.67...  False  \n",
            "4  [[[tensor(0.6745), tensor(0.6784), tensor(0.67...  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "YnKrNliSntF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d439e9b-bb92-482e-ec1c-bb3446cddfc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "False    13090\n",
              "True       417\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(IMAGE_TENSORS_DIR)\n",
        "for i, pt_file_name in enumerate(os.listdir(IMAGE_TENSORS_DIR)):\n",
        "\n",
        "  if i < 43:\n",
        "    continue\n",
        "\n",
        "  elif i < 44:\n",
        "\n",
        "    print(pt_file_name)\n",
        "    start_time = time()\n",
        "\n",
        "    video_number = int(re.search(r'\\d+', pt_file_name).group())\n",
        "    video_frames = os.listdir(f'/content/drive/MyDrive/Object Detection/Videos/video{video_number}/')\n",
        "\n",
        "    for j, image_tensor in enumerate(torch.load(pt_file_name)):\n",
        "      data_df = data_df._append({'Video Number' : video_number,\n",
        "                                 'Frame Number': int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')),\n",
        "                                 'Tensor': image_tensor,\n",
        "                                 'Label': IsPositive(video_number, int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')))}, ignore_index=True)\n",
        "\n",
        "    print(f'Finished {pt_file_name} in {round(time() - start_time, 2)} seconds')\n",
        "\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "id": "EVKB3M8zCCYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is just a quick fix for a problem when creating the dataframel; pls fix when making a new dataframe\n",
        "data_df['Label'] = data_df['Label'].astype(int)"
      ],
      "metadata": {
        "id": "5ds8U2ptKkCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df_test = pd.DataFrame(columns=['Video Number', 'Frame Number', 'Tensor', 'Label'])"
      ],
      "metadata": {
        "id": "VAOjMOfvCTec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(IMAGE_TENSORS_DIR)\n",
        "for i, pt_file_name in enumerate(os.listdir(IMAGE_TENSORS_DIR)):\n",
        "\n",
        "  if i < 44:\n",
        "    continue\n",
        "\n",
        "  elif i < 49:\n",
        "\n",
        "    print(pt_file_name)\n",
        "    start_time = time()\n",
        "\n",
        "    video_number = int(re.search(r'\\d+', pt_file_name).group())\n",
        "    video_frames = os.listdir(f'/content/drive/MyDrive/Object Detection/Videos/video{video_number}/')\n",
        "\n",
        "    for j, image_tensor in enumerate(torch.load(pt_file_name)):\n",
        "      data_df_test = data_df_test._append({'Video Number' : video_number,\n",
        "                                 'Frame Number': int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')),\n",
        "                                 'Tensor': image_tensor,\n",
        "                                 'Label': IsPositive(video_number, int(re.search('frame\\d+', video_frames[j]).group().replace('frame', '')))}, ignore_index=True)\n",
        "\n",
        "    print(f'Finished {pt_file_name} in {round(time() - start_time, 2)} seconds')\n",
        "\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5LdqctUCRDZ",
        "outputId": "8ae2f8b5-42d8-4647-f33f-5f3975ef00e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video44.pt\n",
            "Finished video44.pt in 4.36 seconds\n",
            "video46.pt\n",
            "Finished video46.pt in 13.42 seconds\n",
            "video47.pt\n",
            "Finished video47.pt in 18.93 seconds\n",
            "video48.pt\n",
            "Finished video48.pt in 15.33 seconds\n",
            "video49.pt\n",
            "Finished video49.pt in 18.04 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df_test['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEZrKTscEUUN",
        "outputId": "309a462f-e3ed-4d2f-b85c-68ac8db07be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    6058\n",
              "1     207\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Object Detection/TestTensors')\n",
        "torch.save(data_df_test, 'df_test.pt')"
      ],
      "metadata": {
        "id": "vwCLG8B_DAjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the Dataset"
      ],
      "metadata": {
        "id": "688apV5jSnCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FramesDataset(Dataset):\n",
        "  def __init__(self, data_pd):\n",
        "    self.data_pd = data_pd\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_pd)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data_pd.iloc[index]['Tensor'], self.data_pd.iloc[index]['Label']"
      ],
      "metadata": {
        "id": "fvH51qzvYU6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the DataLoader"
      ],
      "metadata": {
        "id": "RRvMiYuXS1sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FramesDataset(data_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "9h8_6_LCxNcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The Neural Network**"
      ],
      "metadata": {
        "id": "zT9HS-AD3XZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the Neural Network"
      ],
      "metadata": {
        "id": "KU17ordB3hi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 4, 5, 2)\n",
        "        self.conv2 = nn.Conv2d(4, 16, 5, 2)\n",
        "        self.fc1 = nn.Linear(576, 128)\n",
        "        self.fc2 = nn.Linear(128, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 3, 3)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 3, 3)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hcZOOHTD3jhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the Model"
      ],
      "metadata": {
        "id": "bRyaSzo44tOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "8vUu7q0V4urU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "epochs = 4\n",
        "learning_rate = .001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {param_count:,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17duiiS45BV_",
        "outputId": "47e80410-f953-4b5d-a396-441e4e396a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 76,617 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.compile(model, mode=\"reduce-overhead\")\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "wLFa-mWR6LiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
        "    with torch.autocast(device_type=\"cuda\"):\n",
        "        outputs = model(data.to(device))\n",
        "        loss = criterion(outputs, targets.to(device))\n",
        "    print(loss)\n",
        "    break"
      ],
      "metadata": {
        "id": "CtodqVZ678a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times = []\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
        "\n",
        "        start = time()\n",
        "\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "\n",
        "        outputs = model(data.to(device))\n",
        "        loss = criterion(outputs, targets.to(device))\n",
        "        for param in model.parameters():\n",
        "            param.grad = None\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        times.append(time() - start)\n",
        "\n",
        "        msg =  f'Epoch: {epoch+1:02}/{epochs:02} | '\n",
        "        msg += f'Batch: {batch_idx+1:05}/{len(train_dataloader):05} | '\n",
        "        msg += f'Loss: {losses[-1]:0.4} | '\n",
        "        msg += f'Avg Loss: {sum(losses)/len(losses):0.4} | '\n",
        "        msg += f'Time: {times[-1]:0.4} | '\n",
        "        avg_time = sum(times)/len(times)\n",
        "        msg += f'Avg Time: {avg_time:0.4} | '\n",
        "        msg += f'Time Left: {avg_time * (len(train_dataloader) - (batch_idx + 1)):0.4}'\n",
        "        print(msg, flush=True)\n",
        "        if (batch_idx%10 == 0):\n",
        "            torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "WOX19zQN5jje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = Compose((Resize((256, 256)), Grayscale(), ToTensor()))\n",
        "image = transform(Image.open('/content/drive/MyDrive/Object Detection/Videos/video46/frame173.jpeg'))\n",
        "\n",
        "image = image.view(1, 1, 256, 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4merc_0Ewsx",
        "outputId": "68ba9fec-b2e8-4d9f-d183-db68c6eb88ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(image.view(1, 1, 256, 256).to(device))\n",
        "  print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYNkGvLeF5uz",
        "outputId": "9b53592e-de90-4725-8d76-b6a005eb954f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12.5323, -11.9458]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XEVymuaIhjc",
        "outputId": "e2f0a652-81bc-422f-8fe6-608d0d19dc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oasSwyS2BC3W"
      },
      "source": [
        "#**Converting the Images to Tensors**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Useful Libraries"
      ],
      "metadata": {
        "id": "43GKTNgDDLyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "from time import time\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Resize, Grayscale\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "zbOebm_IDKdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mount the Google Drive"
      ],
      "metadata": {
        "id": "FGvGiH3eGWuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7nvynukGa3Z",
        "outputId": "44fcb22e-8f46-4e4a-96b6-864dc02c38e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WMBpOP-A5d3"
      },
      "source": [
        "###Getting the File Paths for EVERY Frame in a Given Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvaJkhTbA5d4"
      },
      "outputs": [],
      "source": [
        "VIDEO_NUMBERS = (48, 49)\n",
        "\n",
        "# The file directories for each video\n",
        "video_directories = [f'/content/drive/MyDrive/Object Detection/Videos/video{video_number}' for video_number in VIDEO_NUMBERS]\n",
        "\n",
        "# List containing the file paths for every frame in specified videos\n",
        "frame_directories = [[os.path.join(video_directory, frame) for frame in os.listdir(video_directory)] for video_directory in video_directories]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5-kVYNsA5d4"
      },
      "source": [
        "###Converting & Storing Image Tensors Into a List"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(r'/content/drive/MyDrive/Object Detection/ImageTensors')\n",
        "transform = Compose((Resize((256, 256)), Grayscale(), ToTensor()))\n",
        "\n",
        "for i in range(len(VIDEO_NUMBERS)):\n",
        "  start_time = time()\n",
        "\n",
        "  image_tensors = [transform(Image.open(path)) for path in frame_directories[i]]\n",
        "\n",
        "  torch.save(image_tensors, f'video{VIDEO_NUMBERS[i]}.pt')\n",
        "  print(f'Saved video #{VIDEO_NUMBERS[i]} in {round((start_time - time()) / 60, 2)} minutes')\n",
        "\n",
        "  gc.collect()\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "NWHjz3UKDXM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/Object Detection/Videos/video40')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "651VTAyPghIQ",
        "outputId": "21ee7efd-dfe4-4a6a-a4bc-286ca6425d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(r'/content/drive/MyDrive/Object Detection/ImageTensors')\n",
        "transform = Compose((Resize((256, 256)), Grayscale(), ToTensor()))\n",
        "\n",
        "\n",
        "start_time = time()\n",
        "image_tensors = []\n",
        "\n",
        "videodir = '/content/drive/MyDrive/Object Detection/Videos/video49'\n",
        "for frame in os.listdir(videodir):\n",
        "  path = os.path.join(videodir, frame)\n",
        "  tensor = transform(Image.open(path))\n",
        "  image_tensors.append(tensor)\n",
        "\n",
        "torch.save(image_tensors, 'video49.pt')\n",
        "print(f'Saved video #49 in {round((start_time - time()) / 60, 2)} minutes')\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZxqI_g0gHcV",
        "outputId": "b4c89dfc-0886-4e76-c62c-c45c1f09e7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video #49 in -1.32 minutes\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}
